```python
#  代码实战解析解  
#  numpy是用来做数据计算的  
#  matplotlib是用来做数据可视化的  
import numpy as np  
import matplotlib.pyplot as plt  
  
#  有监督的机器学习  
#  生成100个随机数，范围在0-1之间  
x = np.random.rand(100, 1)  
# 这里是要模拟出来的数据y是代表真实的数据，所以也就是y_hat + error  
#  生成100个随机数，范围在0-1之间，加上3x+2,相当于预期解加error  
y = 3 * x + 2 + np.random.rand(100, 1)  
#  在x前面加上一列全为1的列，用于计算截距  
x_b = np.c_[np.ones((100, 1)), x]  
# 实现解析解的公式来求解  .T实现矩阵转置  
theta = np.linalg.inv(x_b.T.dot(x_b)).dot(x_b.T).dot(y)  
print(theta) # 打印解析解  
  
#  使用模型去做预测  
x_new = np.array([[0],[2]])  # 添加两行一列的矩阵  
x_new_b = np.c_[np.ones((2, 1)), x_new]  #  添加一列全为1的列，用于计算截距  
y_predict = x_new_b.dot(theta)  #  模型预测,这里就是用解析解的公式来计算，x_new_b.dot(theta) = x_new_b * theta  
print(y_predict) # 打印预测结果  
#  画图进行展示真实的数据点和我们预测用的数据点  
plt.plot(x_new, y_predict, "r-"), plt.plot(x, y, "b.") #  画图，x_new是横坐标，y_predict是纵坐标，"r-"代表红色实线，"b."代表蓝色点  
plt.axis([0,2,0,7]) #  设置x轴和y轴的范围  
plt.show()
```


## 矩阵部分讲解
理解矩阵乘法对于这段代码来说确实很重要。让我解释一下代码中涉及的矩阵运算：

1. `x_b.T.dot(x_b)`：
   - `x_b.T` 是 x_b 的转置
   - `dot()` 方法执行矩阵乘法
   - 这一步计算 X^T * X，其中 X 是包含截距项的特征矩阵

2. `np.linalg.inv(x_b.T.dot(x_b))`：
   - `np.linalg.inv()` 计算矩阵的逆
   - 这一步计算 `(X^T * X)^(-1)`

3. `x_b.T.dot(y)`：
   - 计算 `X^T * y`，其中 y 是目标变量向量

4. `np.linalg.inv(x_b.T.dot(x_b)).dot(x_b.T).dot(y)`：
   - 这整个表达式实现了线性回归的解析解公式：θ = (X^T * X)^(-1) * X^T * y
   - 结果是包含截距和斜率的参数向量 θ

5. `x_new_b.dot(theta)`：
   - 使用计算出的 θ 进行预测
   - 相当于计算 y = θ_0 + θ_1 * x，其中 θ_0 是截距，θ_1 是斜率

这些矩阵运算高效地实现了线性回归的计算过程。使用矩阵运算而不是循环可以大大提高代码的效率，尤其是在处理大型数据集时。
<!--stackedit_data:
eyJoaXN0b3J5IjpbOTMwOTk0NDMxXX0=
-->